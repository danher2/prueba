see
Yes, I fully understand what you‚Äôre trying to do ‚Äî here‚Äôs your process in my own words so we‚Äôre aligned:

---

## **Current Flow**

1. **Initial Mapping**

   * You take the `UnderwritingRequest` and use your `mapper` to produce a `ProtegrityPayload` (`payloadToSend`).
   * This payload‚Äôs `unsecure.alphanum` map contains **tokenized** account values (alphanumeric placeholders).

2. **Protegrity Detokenization Call**

   * You send `payloadToSend` to `ProtegrityService`‚Äôs `invokeProtegrityService`.
   * You get back `ProtegrityPayload response` (`responseFromProtegrity`), whose `unsecure.alphanum` should now contain **real detokenized account values**.

---

## **Problem**

* Sometimes after detokenization, **some accounts are still in alphanumeric/tokenized format** instead of the expected real values.
* These accounts need a **second detokenization attempt** via a different service.

---

## **What You Want to Do**

1. **Identify Problematic Accounts**

   * Inspect `responseFromProtegrity.getUnsecure().alphanum` for any entries that are **still tokenized** (contain alphanumeric placeholders instead of real numbers).
   * For each such entry, **keep the key** (the unique account identifier in the map).

2. **Retrieve Original Values**

   * Use the **keys** from step 1 to go back to `payloadToSend` (the one originally sent to Protegrity).
   * Look up the real intended values for those accounts in **that payload‚Äôs `unsecure.alphanum` map**.

3. **Call Alternative Detokenization Service**

   * Send the **map of account keys ‚Üí original values** to a different detokenization service (your ‚Äúplan B‚Äù service).

4. **Validate New Response**

   * Check the returned values from this alternative service.
   * If any are still alphanumeric, you‚Äôll need to decide what to do (log an error, raise an alert, etc.).

5. **Merge Results**

   * If all accounts are now properly detokenized, **update** the `responseFromProtegrity.getUnsecure().alphanum` map with these newly detokenized values.
   * This way, the final `responseFromProtegrity` has a **complete, fully detokenized set of accounts**.

---

## **Summary**

You are basically implementing a **second-pass correction**:

* First pass = ProtegrityService.
* Second pass (only for failures) = alternative detokenization service.
* Then merge fixed values back into the first response so that downstream code sees a complete result.

---

If you want, I can now design the **exact step-by-step algorithm** that does this inside your existing method without breaking the current structure. That would be the next step before writing the actual code.




package com.yourpkg; // adjust

import java.util.*;
import java.util.function.Predicate;
import java.util.stream.Collectors;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class ProtegrityService {
    private static final Logger log = LoggerFactory.getLogger(ProtegrityService.class);

    // Injected collaborators (adjust names/types to your project)
    private final ProtegrityMapper mapper;
    private final ProtegrityRestClient restClient;
    private final String detokenizeEndpoint;
    private final AlternativeDetokenizeService altDetokenizeService; // your ‚Äúplan B‚Äù service

    public ProtegrityService(ProtegrityMapper mapper,
                             ProtegrityRestClient restClient,
                             String detokenizeEndpoint,
                             AlternativeDetokenizeService altDetokenizeService) {
        this.mapper = mapper;
        this.restClient = restClient;
        this.detokenizeEndpoint = detokenizeEndpoint;
        this.altDetokenizeService = altDetokenizeService;
    }

    public void detokenizeTradelineAccounts(UnderwritingRequest underwritingRequest) throws ProtegrityException {
        // --- 1) Build payload and quick skip if nothing to detokenize ---
        ProtegrityPayload payloadToSend = mapper.detokenizeTradelineAccounts(underwritingRequest);

        boolean hasAccountsToDetokenize = payloadToSend.getUnsecure().stream()
            .filter(Objects::nonNull)
            .map(Unsecure::getAlphanum)
            .filter(Objects::nonNull)
            .anyMatch(m -> !m.isEmpty());

        if (!hasAccountsToDetokenize) {
            log.info("No tradeline accounts to detokenize. Skipping Protegrity call.");
            return;
        }

        // --- 2) Call Protegrity for first-pass detokenization ---
        ProtegrityPayload response = restClient.invokeProtegrityService(payloadToSend, detokenizeEndpoint);
        if (response == null) {
            throw new ProtegrityException("PROT_NULL_RESPONSE", "Protegrity returned null payload");
        }

        // --- 3) Identify entries STILL in alphanumeric/tokenized form in the RESPONSE ---
        // ‚ÄúAlphanumeric‚Äù per your spec: values that still contain at least one LETTER.
        Predicate<String> stillAlphanumeric = this::containsAnyLetter;

        Set<String> keysNeedingSecondPass = response.getUnsecure().stream()
            .filter(Objects::nonNull)
            .map(Unsecure::getAlphanum)
            .filter(Objects::nonNull)
            .flatMap(m -> m.entrySet().stream())
            .filter(e -> stillAlphanumeric.test(nullSafeTrim(e.getValue())))
            .map(Map.Entry::getKey)
            .collect(Collectors.toCollection(LinkedHashSet::new));

        if (keysNeedingSecondPass.isEmpty()) {
            log.info("All accounts detokenized by Protegrity on first pass.");
            mapper.setDetokenizeTradelineAccounts(underwritingRequest, response);
            return;
        }

        log.info("Second pass needed for {} account(s): {}", keysNeedingSecondPass.size(), keysNeedingSecondPass);

        // --- 4) Build key -> ORIGINAL REAL VALUE map FROM THE PAYLOAD YOU SENT ---
        Map<String, String> accountsToRetry = new LinkedHashMap<>();
        for (String key : keysNeedingSecondPass) {
            Optional<String> originalValue = findValueByKeyInPayload(payloadToSend, key);
            if (originalValue.isPresent()) {
                accountsToRetry.put(key, originalValue.get());
            } else {
                log.warn("Key '{}' not found in original payload; skipping from second pass.", key);
            }
        }

        if (accountsToRetry.isEmpty()) {
            log.warn("No accounts could be prepared for second pass (none found in original payload).");
            mapper.setDetokenizeTradelineAccounts(underwritingRequest, response);
            return;
        }

        // --- 5) Call the alternative detokenization/tokenization service (Plan B) ---
        // Expected to return key -> fixedDetokenizedValue
        Map<String, String> fixedAccounts = altDetokenizeService.detokenizeAccounts(accountsToRetry);

        if (fixedAccounts == null || fixedAccounts.isEmpty()) {
            log.warn("Alternative detokenize service returned no results. Proceeding without merge.");
            mapper.setDetokenizeTradelineAccounts(underwritingRequest, response);
            return;
        }

        // --- 6) Filter only truly fixed values (not alphanumeric anymore) ---
        Map<String, String> trulyFixed = fixedAccounts.entrySet().stream()
            .filter(e -> !stillAlphanumeric.test(nullSafeTrim(e.getValue())))
            .collect(Collectors.toMap(Map.Entry::getKey, e -> e.getValue(), (a, b) -> a, LinkedHashMap::new));

        if (trulyFixed.isEmpty()) {
            log.warn("Alternative detokenize returned only alphanumeric values. No merge performed.");
            mapper.setDetokenizeTradelineAccounts(underwritingRequest, response);
            return;
        }

        // --- 7) Merge fixes back into the FIRST response‚Äôs unsecure.alphanum maps ---
        int replaced = 0;
        for (Unsecure u : response.getUnsecure()) {
            if (u == null || u.getAlphanum() == null) continue;
            Map<String, String> map = u.getAlphanum();
            for (Map.Entry<String, String> e : trulyFixed.entrySet()) {
                String k = e.getKey();
                if (map.containsKey(k)) {
                    map.put(k, e.getValue());
                    replaced++;
                }
            }
        }

        log.info("Merged {} fixed account value(s) into the Protegrity response.", replaced);

        // --- 8) Final mapping back into the UnderwritingRequest ---
        mapper.setDetokenizeTradelineAccounts(underwritingRequest, response);
    }

    // ---------- helpers ----------

    private Optional<String> findValueByKeyInPayload(ProtegrityPayload payload, String key) {
        for (Unsecure u : payload.getUnsecure()) {
            if (u == null || u.getAlphanum() == null) continue;
            if (u.getAlphanum().containsKey(key)) {
                return Optional.ofNullable(u.getAlphanum().get(key));
            }
        }
        return Optional.empty();
    }

    private boolean containsAnyLetter(String s) {
        if (s == null || s.isBlank()) return false;
        for (int i = 0; i < s.length(); i++) {
            if (Character.isLetter(s.charAt(i))) return true;
        }
        return false;
    }

    private String nullSafeTrim(String s) {
        return s == null ? null : s.trim();
    }

    // Placeholder for your alternative service:
    public interface AlternativeDetokenizeService {
        Map<String, String> detokenizeAccounts(Map<String, String> keyToOriginalValue);
    }

    // Placeholders for your existing project types:
    public interface ProtegrityRestClient {
        ProtegrityPayload invokeProtegrityService(ProtegrityPayload payload, String endpoint) throws ProtegrityException;
    }
}


Got it üëç You want to rebase your branch on top of the updated master so you can bring in the latest changes. Here‚Äôs the step-by-step:

1. Make sure you‚Äôre on your feature branch
git checkout your-branch

2. Update your local master

Fetch the latest changes from remote:

git fetch origin


Then update local master:

git checkout master
git pull origin master

3. Rebase your branch onto master

Switch back to your branch:

git checkout your-branch


Now rebase:

git rebase master

4. Resolve conflicts (if any)

If conflicts appear:

Git will stop and tell you which files have conflicts.

Open those files, fix conflicts manually.

Mark them as resolved:

git add <file>


Then continue:

git rebase --continue


If you want to cancel the rebase:

git rebase --abort

5. Push changes

If you already pushed your branch before rebasing, you‚Äôll need to force push (since history is rewritten):

git push origin your-branch --force


‚úÖ After this, your branch will sit on top of the latest master commit, no longer one commit behind.

Do you want me to also show you how to do the same thing inside GitLab UI / MR page (using the ‚ÄúRebase‚Äù button) or just stick with the CLI steps?
